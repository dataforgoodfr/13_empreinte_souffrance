{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74364b9-0eee-4c6e-beb7-0bdeb73b1536",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ce document r√©sume les jeu de donn√©es, m√©thodologie, et statistiques utilis√©es pour l'estimation de la souffrance contenue dans les bo√Ætes d'oeufs.\n",
    "\n",
    "Nous commen√ßons par l'import de la base de donn√©es compl√®te d'open food facts obtenue le 31 mars 2025.\n",
    "\n",
    "De cette base de donn√©es, nous ne retenons que les colonnes (goodcol) n√©cessaires au calcul du poids de souffrance, telles que d√©finies dans le code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2001deb5-6c98-4442-8aa3-e8e91b9d521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Any\n",
    "import logging\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "sys.path.insert(0, \"../../backend\")\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8806eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs_from_parquet = pd.read_csv(\"../data/eggs_from_parquet.csv\")\n",
    "eggs_from_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef88ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_json_loads(s):\n",
    "    if isinstance(s, str):\n",
    "        s_strip = s.strip()\n",
    "        if s_strip.startswith(('[', '{')):\n",
    "            try:\n",
    "                return json.loads(s_strip)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    return s\n",
    "\n",
    "with open(\"../data/cols_to_json.txt\", \"r\") as f:\n",
    "    cols_to_json = json.load(f)\n",
    "\n",
    "for col in cols_to_json:\n",
    "    eggs_from_parquet[col] = eggs_from_parquet[col].apply(safe_json_loads)\n",
    "\n",
    "eggs_from_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d53e5-01dd-4001-b4d3-b117bbb3c72d",
   "metadata": {},
   "source": [
    "## R√©sultats\n",
    "\n",
    "On obtient par cette m√©thode 6228 √©l√©ments, soit plus du double.\n",
    "\n",
    "Des dix √©l√©ments affich√©s, on r√©cup√®re surtour des oeufs, mais il y a des faux positifs, par exemple 0012009012168 : Chef d'oeuf‚Ñ¢avec fromage sur muffin anglais, qui du reste ne serait pas exclu non plus en cherchant \"oeuf\" dans le champ \"product_name\".\n",
    "\n",
    "En revanche, en √©chantillonnant 50 autres √©l√©ments, il semble que les √©l√©ments aberrants soient rares, et qu'on ait surtout, √† part les packs, des blancs d'oeufs, qui ne posent pas de probl√®me.\n",
    "\n",
    "Ce filtre pourra √™tre utilis√© dans le code principal pour filtrer les √©l√©ments ; nous le conservons dans la suite de cette √©tude en gardant √† l'esprit que quelques pourcents des r√©sultats peuvent √™tre incorrects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfe887",
   "metadata": {},
   "source": [
    "## Import de l'OCR\n",
    "\n",
    "On importe l'analyse par OCR de toutes les images d'oeufs + pr√©dictions de cat√©gories, en vue d'un parsing par regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f31592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class JSONLProcessor:\n",
    "    \"\"\"A class to process JSONL files and convert them to pandas DataFrames.\"\"\"\n",
    "    \n",
    "    DEFAULT_COLUMNS = [\n",
    "        'code', 'texte_ocr', 'breeding_type_related', 'weight_related',\n",
    "        'proba_1', 'proba_2', 'proba_3'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the JSONL processor.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the .jsonl file\n",
    "        \"\"\"\n",
    "        self.file_path = Path(file_path)\n",
    "        self.processed_data: List[Dict[str, Any]] = []\n",
    "    \n",
    "    def _validate_file(self) -> bool:\n",
    "        \"\"\"\n",
    "        Validate if the file exists and is readable.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if file is valid, False otherwise\n",
    "        \"\"\"\n",
    "        if not self.file_path.exists():\n",
    "            logger.error(f\"File '{self.file_path}' not found\")\n",
    "            return False\n",
    "        \n",
    "        if not self.file_path.is_file():\n",
    "            logger.error(f\"'{self.file_path}' is not a file\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "                f.read(1)  # Try to read first character\n",
    "            return True\n",
    "        except (PermissionError, UnicodeDecodeError) as e:\n",
    "            logger.error(f\"Cannot read file '{self.file_path}': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _extract_nested_field(self, record: Dict, *keys: str, default: Any = None) -> Any:\n",
    "        \"\"\"\n",
    "        Safely extract nested fields from a dictionary.\n",
    "        \n",
    "        Args:\n",
    "            record (Dict): The dictionary to extract from\n",
    "            *keys: Sequence of keys to traverse\n",
    "            default: Default value if any key is missing\n",
    "            \n",
    "        Returns:\n",
    "            The extracted value or default\n",
    "        \"\"\"\n",
    "        current = record\n",
    "        for key in keys:\n",
    "            if isinstance(current, dict) and key in current:\n",
    "                current = current[key]\n",
    "            else:\n",
    "                return default\n",
    "        return current\n",
    "    \n",
    "    def _process_record(self, record: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a single JSON record and extract required fields.\n",
    "        \n",
    "        Args:\n",
    "            record (Dict): JSON record to process\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Processed record with extracted fields\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'code': record.get('code', {}),\n",
    "            'texte_ocr': record.get('ocr_text', {}),\n",
    "            'breeding_type_related': self._extract_nested_field(\n",
    "                record, 'groq_spans', 'breeding_type_related', default={}\n",
    "            ),\n",
    "            'weight_related': self._extract_nested_field(\n",
    "                record, 'groq_spans', 'weight_related', default={}\n",
    "            ),\n",
    "            'proba_1': self._extract_nested_field(\n",
    "                record, 'lewagon_prediction', 'proba_1'\n",
    "            ),\n",
    "            'proba_2': self._extract_nested_field(\n",
    "                record, 'lewagon_prediction', 'proba_2'\n",
    "            ),\n",
    "            'proba_3': self._extract_nested_field(\n",
    "                record, 'lewagon_prediction', 'proba_3'\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def _process_line(self, line: str, line_num: int) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Process a single line from the JSONL file.\n",
    "        \n",
    "        Args:\n",
    "            line (str): Line to process\n",
    "            line_num (int): Line number for error reporting\n",
    "            \n",
    "        Returns:\n",
    "            Optional[Dict]: Processed record or None if error occurred\n",
    "        \"\"\"\n",
    "        stripped_line = line.strip()\n",
    "        if not stripped_line:\n",
    "            logger.debug(f\"Line {line_num} is empty, skipping\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            record = json.loads(stripped_line)\n",
    "            return self._process_record(record)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.warning(f\"JSON decode error at line {line_num}: {e}\")\n",
    "            logger.debug(f\"Problematic line: {stripped_line[:100]}...\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Unexpected error processing line {line_num}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_file(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process the entire JSONL file and return a DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with extracted data\n",
    "        \"\"\"\n",
    "        if not self._validate_file():\n",
    "            return pd.DataFrame(columns=self.DEFAULT_COLUMNS)\n",
    "        \n",
    "        self.processed_data = []\n",
    "        successful_lines = 0\n",
    "        total_lines = 0\n",
    "        \n",
    "        try:\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "                logger.info(f\"Processing file: {self.file_path}\")\n",
    "                for line_num, line in enumerate(f, 1):\n",
    "                    total_lines += 1\n",
    "                    processed_record = self._process_line(line, line_num)\n",
    "                    if processed_record is not None:\n",
    "                        self.processed_data.append(processed_record)\n",
    "                        successful_lines += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error reading file: {e}\")\n",
    "            return pd.DataFrame(columns=self.DEFAULT_COLUMNS)\n",
    "        \n",
    "        logger.info(f\"Processing complete. Successfully processed {successful_lines}/{total_lines} lines\")\n",
    "        return pd.DataFrame(self.processed_data)\n",
    "\n",
    "\n",
    "def create_dataframe_from_jsonl(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame from a JSONL file.\n",
    "    \n",
    "    This function extracts specific fields from each JSON record:\n",
    "    - code, ocr_text from root level\n",
    "    - breeding_type_related, weight_related from groq_spans\n",
    "    - proba_1, proba_2, proba_3 from lewagon_prediction\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .jsonl file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with extracted data, or empty DataFrame if error occurs\n",
    "    \"\"\"\n",
    "    processor = JSONLProcessor(file_path)\n",
    "    return processor.process_file()\n",
    "\n",
    "\n",
    "# Configuration\n",
    "JSONL_FILE_PATH = r\"..\\neural_category_predictions\\data\\dfoeufs_with_predictions_with_ground_truth_with_groq.jsonl\"\n",
    "\n",
    "# Process the file\n",
    "try:\n",
    "    code_ocr = create_dataframe_from_jsonl(JSONL_FILE_PATH)\n",
    "    \n",
    "    if not code_ocr.empty:\n",
    "        print(f\"DataFrame created successfully with {len(code_ocr)} rows and {len(code_ocr.columns)} columns\")\n",
    "        display(code_ocr)\n",
    "    else:\n",
    "        print(\"Empty DataFrame created - check file path and content\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process file: {e}\")\n",
    "\n",
    "print(\"Merge avec l'import eggs, renomm√© eggs\")\n",
    "eggs = eggs_from_parquet.merge(code_ocr, on='code', how = 'left')\n",
    "eggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86309fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs['texte_ocr'] = eggs['texte_ocr'].str.replace(r'\\n|\\r\\n|\\r', ' . ', regex=True).str.lower()\n",
    "eggs['texte_ocr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e84516",
   "metadata": {},
   "source": [
    "# Analyse OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc35858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.enums.open_food_facts.breeding_type_enums import (\n",
    "    COUNTRIES_WHERE_CAGES_ARE_FURNISHED,\n",
    "    get_barn_regex,\n",
    "    get_cage_regex,\n",
    "    get_free_range_regex,\n",
    "    BREEDING_PATTERNS_ALL_LANGUAGES,\n",
    "    FREE_RANGE_BREEDINGS,\n",
    ")\n",
    "from app.enums.open_food_facts.enums import AnimalType, BreedingType, LayingHenBreedingType\n",
    "from app.schemas.open_food_facts.external import ProductData\n",
    "from app.schemas.open_food_facts.internal import ProductType\n",
    "from app.business.open_food_facts.egg_weight_calculator import get_number_of_eggs\n",
    "from app.business.open_food_facts.breeding_type_calculator import BreedingTypeCalculator\n",
    "from app.business.open_food_facts.egg_weight_calculator import get_egg_weight_from_quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regex(breeding_type) -> str:\n",
    "    \"\"\"\n",
    "    Constructs a regex pattern that matches 'barn' breeding types.\n",
    "    Here no need for exclusions\n",
    "    Returns:\n",
    "        str: A regex pattern that matches any of the 'barn' breeding types.\n",
    "    \"\"\"\n",
    "    if breeding_type == \"free-range\":\n",
    "        set_all_free_range_not_organic = set()\n",
    "        for breeding in FREE_RANGE_BREEDINGS:\n",
    "            if breeding == \"organic\":\n",
    "                continue\n",
    "            set_all_free_range_not_organic.update(BREEDING_PATTERNS_ALL_LANGUAGES[breeding])\n",
    "        return r\"\\b(?:\" + \"|\".join(set_all_free_range_not_organic) + r\")\\b\"\n",
    "\n",
    "    else:\n",
    "        return r\"\\b(?:\" + \"|\".join(BREEDING_PATTERNS_ALL_LANGUAGES[breeding_type]) + r\")\\b\"\n",
    "\n",
    "\n",
    "def clean(s: str | None) -> str:\n",
    "    \"\"\"\n",
    "    Cleans a string by removing accents, replacing punctuation and digits,\n",
    "    converting to lowercase, and replacing '≈ì' with 'oe' before regex matching.\n",
    "    Args:     s (str | None): The string to clean.\n",
    "\n",
    "    Returns:  str: The cleaned string.\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(s):\n",
    "        return ''\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.lower().replace(\"≈ì\", \"oe\").replace(\"\\n\", \" \")\n",
    "    s = unicodedata.normalize(\"NFD\", s)\n",
    "    s = \"\".join(c for c in s if unicodedata.category(c) != \"Mn\")\n",
    "    s = re.sub(r\"[^\\w\\s]|\\d+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "eggs['cage_from_OCR'] = eggs['breeding_type_related'].apply(clean).str.findall(get_regex('cage'))\n",
    "eggs['cage_from_OCR_2'] = eggs['texte_ocr'].apply(clean).str.findall(get_regex('cage'))\n",
    "eggs['barn_from_OCR'] = eggs['breeding_type_related'].apply(clean).str.findall(get_regex('barn'))\n",
    "eggs['barn_from_OCR_2'] = eggs['texte_ocr'].apply(clean).str.findall(get_regex('barn'))\n",
    "eggs['free_range_from_OCR'] = eggs['breeding_type_related'].apply(clean).str.findall(get_regex('free-range'))\n",
    "eggs['free_range_from_OCR_2'] = eggs['texte_ocr'].apply(clean).str.findall(get_regex('free-range'))\n",
    "eggs['organic_from_OCR'] = eggs['breeding_type_related'].apply(clean).str.findall(get_regex('organic'))\n",
    "eggs['organic_from_OCR_2'] = eggs['texte_ocr'].apply(clean).str.findall(get_regex('organic'))\n",
    "\n",
    "\n",
    "eggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs['weight_from_OCR'] = eggs['weight_related'].apply(lambda x: 0 if pd.isna(x) else  get_egg_weight_from_quantity(x))\n",
    "eggs['quantity_from_OCR'] = eggs['weight_related'].apply(lambda x: 0 if pd.isna(x) else  get_egg_weight_from_quantity(x)/50)\n",
    "eggs['size_from_OCR'] = \"\"\n",
    "\n",
    "eggs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a356f",
   "metadata": {},
   "source": [
    "# Proportion d'oeufs identifi√©s\n",
    "\n",
    "Nous r√©cup√©rons les fonctions correspondantes dans le code principal, et d√©finissons quelques fonctions utilitaires de conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c98f1-90eb-4ca0-a0fb-04d09bb4a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import app.business.open_food_facts.pain_report_calculator as prc\n",
    "from app.schemas.open_food_facts.external import ProductData\n",
    "from app.business.open_food_facts.egg_weight_calculator import calculate_egg_weight\n",
    "\n",
    "\n",
    "def is_egg_packb(product_data: ProductData, strict=False) -> bool:\n",
    "    \"\"\"\n",
    "    Quick function to check whether we're dealing with egg pack\n",
    "    product_data : product data\n",
    "    strict: if true, returns only \"en:chicken-eggs\" in category,\n",
    "    otherwise must have \"en:eggs\" but not other identified animals.\n",
    "\n",
    "    Returns:\n",
    "        True if egg, False if ovoproduct or otherwise\n",
    "    \"\"\"\n",
    "    tags=product_data.categories_tags\n",
    "    if tags is None:\n",
    "        return False\n",
    "    elif 'en:eggs' not in tags:\n",
    "        return False\n",
    "    elif strict:\n",
    "        return  \"en:chicken-eggs\" in tags\n",
    "    else:\n",
    "        no_chicken={'en:chocolate-eggs',\n",
    "            'en:duck-eggs',\n",
    "            'en:easter-eggs',\n",
    "            'en:fish-eggs',\n",
    "            'en:free-range-duck-eggs',\n",
    "            'en:quail-eggs',\n",
    "            'en:raw-quail-eggs',\n",
    "            'en:savoury-eggs',\n",
    "            'en:scotch-eggs',\n",
    "            'en:streamed-eggs',\n",
    "            'en:meals',\n",
    "            'en:snacks',\n",
    "            'en:meats-and-their-products',\n",
    "            'en:breads'\n",
    "        }\n",
    "        return len(no_chicken.intersection(tags)) == 0\n",
    "        \n",
    "def clean_value(val):\n",
    "    if isinstance(val, (list, dict)):\n",
    "        return val  # on ne touche pas aux objets JSON d√©s√©rialis√©s\n",
    "    else:\n",
    "        return None if pd.isna(val) else val\n",
    "\n",
    "\n",
    "def row2productdata(row):\n",
    "    drow=row.to_dict()\n",
    "\n",
    "    for key in drow:\n",
    "        drow[key] = clean_value(drow[key])\n",
    "\n",
    "    if drow[\"ingredients\"] is not None:\n",
    "        drow[\"ingredients\"]=(drow[\"ingredients\"])\n",
    "    if len(drow[\"product_name\"])>0:\n",
    "        drow[\"product_name\"]=drow[\"product_name\"][0][\"text\"]\n",
    "    else:\n",
    "        drow[\"product_name\"]=\"\"\n",
    "    if len(drow[\"generic_name\"])>0:\n",
    "        drow[\"generic_name\"]=drow[\"generic_name\"][0][\"text\"]\n",
    "    else:\n",
    "        drow[\"generic_name\"]=\"\"\n",
    "    product_data=ProductData.model_validate(drow)\n",
    "    return product_data\n",
    "\n",
    "def row2number(row):\n",
    "    product_data=row2productdata(row)\n",
    "    return calculate_egg_weight(product_data)\n",
    "\n",
    "\n",
    "def row2breedingtype(row):\n",
    "    product_data=row2productdata(row)\n",
    "    report=prc.PainReportCalculator(product_data)\n",
    "    gbt=report._get_breeding_types()\n",
    "    return gbt['laying_hen'].value if 'laying_hen' in gbt else \"None\"\n",
    "\n",
    "\n",
    "def testrow(df, nrow):\n",
    "    row=df.iloc[nrow]\n",
    "    return row2number, row2breedingtype(row), row\n",
    "\n",
    "\n",
    "testrow(eggs, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d7091-ea62-411c-80d8-b0a0e06bd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs['w_eggs'] = eggs.apply(row2number, axis=1)\n",
    "eggs['breeding'] = eggs.apply(row2breedingtype, axis=1)\n",
    "eggs[\"product_quantity\"]=eggs[\"product_quantity\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed7563-70b9-487a-9860-726f62e929b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs.breeding.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0ed94-7729-4c67-96c4-16660f3f40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"en:france\" in eggs[\"countries_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f4982-152d-4823-b83c-5d031cda11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs.groupby('w_eggs').agg( sample=('code', lambda x: x.head(10).tolist()), w_eggs=('w_eggs', lambda x: x.head(10).tolist()),  total_count=('w_eggs', 'size') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5f9c6-8b2c-438d-a0b8-7bd4bff799b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs[\"has_breeding_type\"]=eggs[\"breeding\"].apply(lambda x: \"computed\" if x == \"barn\" or x == \"furnished_cage\" or x == \"conventional_cage\" else \"Aucun\" if x == \"None\" else x)\n",
    "eggs[\"has_egg_weight\"]= eggs[\"w_eggs\"]>0 & ~eggs[\"w_eggs\"].isna()\n",
    "eggs[\"has_egg_weight_s\"] = eggs[\"has_egg_weight\"].apply(lambda x: \"has weight\" if x else \"no weight\")\n",
    "eggs[\"french\"]=eggs[\"countries_tags\"].fillna(\"\").apply(lambda x:  len(x)>0 and \"en:france\" in x)\n",
    "eggs[\"french_s\"]=eggs[\"french\"].apply(lambda x: \"fran√ßais\" if x else \"pas fran√ßais\")\n",
    "eggs[[\"has_breeding_type\", \"has_egg_weight\"]].value_counts().to_frame().unstack().fillna(0).astype(int).style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e6101-10b3-4650-a92f-28ae0526d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs[[\"breeding\", \"has_egg_weight\"]].value_counts(normalize=True).to_frame().unstack().fillna(0).style.format('{:.1%}').background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf02cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs_fr = eggs[eggs[\"french\"]]\n",
    "eggs_fr.to_csv(\"../data/eggs_is_suffering_computed_fr.csv\", index=False)\n",
    "eggs.to_csv(\"../data/eggs_is_suffering_computed.csv\", index=False)\n",
    "eggs_fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257215f-d92d-40ad-86fb-e2fd8d7526a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(\n",
    "    eggs,\n",
    "    path=[px.Constant(\"all\"), 'french_s', 'has_egg_weight_s', 'has_breeding_type']\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate=\"%{label} : %{value}\")\n",
    "\n",
    "# üîç Agrandir la figure\n",
    "fig.update_layout(\n",
    "    title = \"All eggs : is french, has weight, has breeding type - World\",\n",
    "    width=600,   # Largeur en pixels\n",
    "    height=600,   # Hauteur en pixels\n",
    "    margin=dict(t=40, l=10, r=10, b=10)  # R√©duit les marges pour maximiser l‚Äôespace utile\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.sunburst(\n",
    "    eggs_fr,\n",
    "    path=[px.Constant(\"all\"), 'has_egg_weight_s', 'has_breeding_type']\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate=\"%{label}<br>%{percentRoot:.1%}<br>%{value}\",\n",
    "    textfont=dict(size=12),\n",
    "    insidetextorientation='horizontal'\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"French eggs : has weight, has breeding type\",\n",
    "    width=500,\n",
    "    height=500,\n",
    "    margin=dict(t=40, l=10, r=10, b=10)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ec421",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(\n",
    "    eggs,\n",
    "    path=[px.Constant(\"all\"), 'has_egg_weight_s', 'has_breeding_type']\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate=\"%{label}<br>%{percentRoot:.1%}<br>%{value}\",\n",
    "    textfont=dict(size=12),\n",
    "    insidetextorientation='horizontal'\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"All eggs (World) : has weight, has breeding type\",\n",
    "    width=500,\n",
    "    height=500,\n",
    "    margin=dict(t=40, l=10, r=10, b=10)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
